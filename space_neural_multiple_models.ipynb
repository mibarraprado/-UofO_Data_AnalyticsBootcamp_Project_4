{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"KcmYRYab_j19","executionInfo":{"status":"ok","timestamp":1685590065276,"user_tz":420,"elapsed":3763,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}}},"outputs":[],"source":["# Import our dependencies\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"RGCDkCrg_j1-","executionInfo":{"status":"ok","timestamp":1685590066846,"user_tz":420,"elapsed":205,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"c11e3b31-b81a-4cf4-86ba-5c6d5df73534"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  HomePlanet  CryoSleep Deck  RoomNum Side  Destination   Age    VIP  \\\n","0     Europa      False    B        0    P  TRAPPIST-1e  39.0  False   \n","1      Earth      False    F        0    S  TRAPPIST-1e  24.0  False   \n","2     Europa      False    A        0    S  TRAPPIST-1e  58.0   True   \n","3     Europa      False    A        0    S  TRAPPIST-1e  33.0  False   \n","4      Earth      False    F        1    S  TRAPPIST-1e  16.0  False   \n","\n","   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  Transported  \n","0          0.0        0.0           0.0     0.0     0.0        False  \n","1        109.0        9.0          25.0   549.0    44.0         True  \n","2         43.0     3576.0           0.0  6715.0    49.0        False  \n","3          0.0     1283.0         371.0  3329.0   193.0        False  \n","4        303.0       70.0         151.0   565.0     2.0         True  "],"text/html":["\n","  <div id=\"df-0647e6b6-9012-41f8-a910-ce44abcb0566\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HomePlanet</th>\n","      <th>CryoSleep</th>\n","      <th>Deck</th>\n","      <th>RoomNum</th>\n","      <th>Side</th>\n","      <th>Destination</th>\n","      <th>Age</th>\n","      <th>VIP</th>\n","      <th>RoomService</th>\n","      <th>FoodCourt</th>\n","      <th>ShoppingMall</th>\n","      <th>Spa</th>\n","      <th>VRDeck</th>\n","      <th>Transported</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>B</td>\n","      <td>0</td>\n","      <td>P</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>39.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Earth</td>\n","      <td>False</td>\n","      <td>F</td>\n","      <td>0</td>\n","      <td>S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>24.0</td>\n","      <td>False</td>\n","      <td>109.0</td>\n","      <td>9.0</td>\n","      <td>25.0</td>\n","      <td>549.0</td>\n","      <td>44.0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>A</td>\n","      <td>0</td>\n","      <td>S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>58.0</td>\n","      <td>True</td>\n","      <td>43.0</td>\n","      <td>3576.0</td>\n","      <td>0.0</td>\n","      <td>6715.0</td>\n","      <td>49.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>A</td>\n","      <td>0</td>\n","      <td>S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>33.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>1283.0</td>\n","      <td>371.0</td>\n","      <td>3329.0</td>\n","      <td>193.0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Earth</td>\n","      <td>False</td>\n","      <td>F</td>\n","      <td>1</td>\n","      <td>S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>16.0</td>\n","      <td>False</td>\n","      <td>303.0</td>\n","      <td>70.0</td>\n","      <td>151.0</td>\n","      <td>565.0</td>\n","      <td>2.0</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0647e6b6-9012-41f8-a910-ce44abcb0566')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0647e6b6-9012-41f8-a910-ce44abcb0566 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0647e6b6-9012-41f8-a910-ce44abcb0566');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["cleaned_df = pd.read_csv(\"/titanic.csv\")\n","cleaned_df.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"dC6euA2T_j1-","executionInfo":{"status":"ok","timestamp":1685590079878,"user_tz":420,"elapsed":170,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"ce29d6e4-1f47-4fd2-daba-bd04e771e649"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   CryoSleep  RoomNum   Age    VIP  RoomService  FoodCourt  ShoppingMall  \\\n","0      False        0  39.0  False          0.0        0.0           0.0   \n","1      False        0  24.0  False        109.0        9.0          25.0   \n","2      False        0  58.0   True         43.0     3576.0           0.0   \n","3      False        0  33.0  False          0.0     1283.0         371.0   \n","4      False        1  16.0  False        303.0       70.0         151.0   \n","\n","      Spa  VRDeck  Transported  ...  Deck_D  Deck_E  Deck_F  Deck_G  Deck_T  \\\n","0     0.0     0.0        False  ...       0       0       0       0       0   \n","1   549.0    44.0         True  ...       0       0       1       0       0   \n","2  6715.0    49.0        False  ...       0       0       0       0       0   \n","3  3329.0   193.0        False  ...       0       0       0       0       0   \n","4   565.0     2.0         True  ...       0       0       1       0       0   \n","\n","   Side_P  Side_S  Destination_55 Cancri e  Destination_PSO J318.5-22  \\\n","0       1       0                        0                          0   \n","1       0       1                        0                          0   \n","2       0       1                        0                          0   \n","3       0       1                        0                          0   \n","4       0       1                        0                          0   \n","\n","   Destination_TRAPPIST-1e  \n","0                        1  \n","1                        1  \n","2                        1  \n","3                        1  \n","4                        1  \n","\n","[5 rows x 26 columns]"],"text/html":["\n","  <div id=\"df-49501121-e229-45cb-9f8f-0e5f1f4b457e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CryoSleep</th>\n","      <th>RoomNum</th>\n","      <th>Age</th>\n","      <th>VIP</th>\n","      <th>RoomService</th>\n","      <th>FoodCourt</th>\n","      <th>ShoppingMall</th>\n","      <th>Spa</th>\n","      <th>VRDeck</th>\n","      <th>Transported</th>\n","      <th>...</th>\n","      <th>Deck_D</th>\n","      <th>Deck_E</th>\n","      <th>Deck_F</th>\n","      <th>Deck_G</th>\n","      <th>Deck_T</th>\n","      <th>Side_P</th>\n","      <th>Side_S</th>\n","      <th>Destination_55 Cancri e</th>\n","      <th>Destination_PSO J318.5-22</th>\n","      <th>Destination_TRAPPIST-1e</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>39.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>24.0</td>\n","      <td>False</td>\n","      <td>109.0</td>\n","      <td>9.0</td>\n","      <td>25.0</td>\n","      <td>549.0</td>\n","      <td>44.0</td>\n","      <td>True</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>58.0</td>\n","      <td>True</td>\n","      <td>43.0</td>\n","      <td>3576.0</td>\n","      <td>0.0</td>\n","      <td>6715.0</td>\n","      <td>49.0</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>33.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>1283.0</td>\n","      <td>371.0</td>\n","      <td>3329.0</td>\n","      <td>193.0</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>1</td>\n","      <td>16.0</td>\n","      <td>False</td>\n","      <td>303.0</td>\n","      <td>70.0</td>\n","      <td>151.0</td>\n","      <td>565.0</td>\n","      <td>2.0</td>\n","      <td>True</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 26 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49501121-e229-45cb-9f8f-0e5f1f4b457e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-49501121-e229-45cb-9f8f-0e5f1f4b457e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-49501121-e229-45cb-9f8f-0e5f1f4b457e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["#use getdummies() to convert categorical data to numerical data\n","cleaned_df_prep = pd.get_dummies(cleaned_df)\n","cleaned_df_prep.head()\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"XgO8A63W_j1-","executionInfo":{"status":"ok","timestamp":1685590082071,"user_tz":420,"elapsed":2,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}}},"outputs":[],"source":["# removing the target column Transported from X\n","y = cleaned_df_prep[\"Transported\"].values\n","X = cleaned_df_prep.drop([\"Transported\"],axis=1).values\n","\n","# Splitting into Train and Test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, stratify=y)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ho5Ctc_B_j1-","executionInfo":{"status":"ok","timestamp":1685590085472,"user_tz":420,"elapsed":302,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}}},"outputs":[],"source":[" # Preprocess numerical data for neural network\n","\n","# Create a StandardScaler instances\n","scaler = StandardScaler()\n","\n","# Fit the StandardScaler\n","X_scaler = scaler.fit(X_train)\n","\n","# Scale the data\n","X_train_scaled = X_scaler.transform(X_train)\n","X_test_scaled = X_scaler.transform(X_test)"]},{"cell_type":"code","source":["# define the deep learning model Loss: 0.3851335644721985, Accuracy: 0.822590172290802\n","\n","nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"id":"DI_o_huBDFlK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vlCcT2io_j1_","executionInfo":{"status":"ok","timestamp":1685590547677,"user_tz":420,"elapsed":21559,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"cfbfd34e-17be-419b-b269-278045d626c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","159/159 [==============================] - 1s 1ms/step - loss: 0.5999 - accuracy: 0.6854\n","Epoch 2/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7885\n","Epoch 3/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7905\n","Epoch 4/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7968\n","Epoch 5/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8037\n","Epoch 6/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8003\n","Epoch 7/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4129 - accuracy: 0.7993\n","Epoch 8/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.8074\n","Epoch 9/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8043\n","Epoch 10/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.8050\n","Epoch 11/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4053 - accuracy: 0.8062\n","Epoch 12/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8021\n","Epoch 13/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4053 - accuracy: 0.8029\n","Epoch 14/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4038 - accuracy: 0.8050\n","Epoch 15/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8029\n","Epoch 16/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8098\n","Epoch 17/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8048\n","Epoch 18/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4004 - accuracy: 0.8060\n","Epoch 19/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3962 - accuracy: 0.8047\n","Epoch 20/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3981 - accuracy: 0.8058\n","Epoch 21/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8064\n","Epoch 22/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8106\n","Epoch 23/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8078\n","Epoch 24/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8102\n","Epoch 25/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8070\n","Epoch 26/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8092\n","Epoch 27/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8137\n","Epoch 28/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8123\n","Epoch 29/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3902 - accuracy: 0.8094\n","Epoch 30/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.8116\n","Epoch 31/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8098\n","Epoch 32/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.8117\n","Epoch 33/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8117\n","Epoch 34/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8149\n","Epoch 35/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3842 - accuracy: 0.8127\n","Epoch 36/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3863 - accuracy: 0.8088\n","Epoch 37/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3849 - accuracy: 0.8129\n","Epoch 38/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8137\n","Epoch 39/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3832 - accuracy: 0.8082\n","Epoch 40/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8171\n","Epoch 41/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3808 - accuracy: 0.8110\n","Epoch 42/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3770 - accuracy: 0.8196\n","Epoch 43/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8161\n","Epoch 44/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3746 - accuracy: 0.8171\n","Epoch 45/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8185\n","Epoch 46/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.8173\n","Epoch 47/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3752 - accuracy: 0.8179\n","Epoch 48/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8186\n","Epoch 49/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8171\n","Epoch 50/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8173\n","53/53 - 0s - loss: 0.3885 - accuracy: 0.8096 - 135ms/epoch - 3ms/step\n","Loss: 0.3885054886341095, Accuracy: 0.8095801472663879\n"]}],"source":[" # Define the deep learning model Accuracy: 0.8219988346099854, Loss: 0.3860379457473755,\n","nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"]},{"cell_type":"code","source":["#messing around with adding layers \n","nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"id":"ISljcupgCt2k"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_iw8voV_j1_","executionInfo":{"status":"ok","timestamp":1685590144742,"user_tz":420,"elapsed":12888,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"b84a0f70-6acb-4302-cf95-9f208b83a3fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","159/159 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7345\n","Epoch 2/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7828\n","Epoch 3/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7942\n","Epoch 4/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7922\n","Epoch 5/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7978\n","Epoch 6/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.7995\n","Epoch 7/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.8005\n","Epoch 8/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8037\n","Epoch 9/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4018 - accuracy: 0.8084\n","Epoch 10/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3983 - accuracy: 0.8112\n","Epoch 11/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8078\n","Epoch 12/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8088\n","Epoch 13/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8116\n","Epoch 14/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8064\n","Epoch 15/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8131\n","Epoch 16/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.8129\n","Epoch 17/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.8106\n","Epoch 18/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8133\n","Epoch 19/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8121\n","Epoch 20/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3815 - accuracy: 0.8133\n","Epoch 21/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3821 - accuracy: 0.8153\n","Epoch 22/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8145\n","Epoch 23/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8185\n","Epoch 24/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3791 - accuracy: 0.8183\n","Epoch 25/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3776 - accuracy: 0.8188\n","Epoch 26/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.8186\n","Epoch 27/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3761 - accuracy: 0.8169\n","Epoch 28/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8230\n","Epoch 29/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8137\n","Epoch 30/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8240\n","Epoch 31/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8181\n","Epoch 32/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3656 - accuracy: 0.8212\n","Epoch 33/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8230\n","Epoch 34/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8240\n","Epoch 35/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8230\n","Epoch 36/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.8202\n","Epoch 37/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.8230\n","Epoch 38/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8228\n","Epoch 39/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3574 - accuracy: 0.8295\n","Epoch 40/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8224\n","Epoch 41/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8259\n","Epoch 42/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3563 - accuracy: 0.8279\n","Epoch 43/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.8255\n","Epoch 44/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8311\n","Epoch 45/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.8287\n","Epoch 46/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8273\n","Epoch 47/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3490 - accuracy: 0.8269\n","Epoch 48/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.8301\n","Epoch 49/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8271\n","Epoch 50/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8291\n","53/53 - 0s - loss: 0.3857 - accuracy: 0.8143 - 194ms/epoch - 4ms/step\n","Loss: 0.3856719732284546, Accuracy: 0.8143110871315002\n"]}],"source":["# changing the second layer to relu\n","# Loss: 0.3856719732284546, Accuracy: 0.8143110871315002\n","nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DEyHQuMQ_j1_","executionInfo":{"status":"ok","timestamp":1685590242965,"user_tz":420,"elapsed":14547,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"7491fade-868c-467b-9ba3-494b41dcffe3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","159/159 [==============================] - 1s 2ms/step - loss: 0.5173 - accuracy: 0.7406\n","Epoch 2/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7838\n","Epoch 3/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.7881\n","Epoch 4/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.7940\n","Epoch 5/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7987\n","Epoch 6/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7976\n","Epoch 7/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.7989\n","Epoch 8/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8047\n","Epoch 9/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8025\n","Epoch 10/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4000 - accuracy: 0.8080\n","Epoch 11/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8086\n","Epoch 12/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8021\n","Epoch 13/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8082\n","Epoch 14/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3943 - accuracy: 0.8104\n","Epoch 15/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8070\n","Epoch 16/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8110\n","Epoch 17/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8157\n","Epoch 18/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8074\n","Epoch 19/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8117\n","Epoch 20/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8167\n","Epoch 21/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8151\n","Epoch 22/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8159\n","Epoch 23/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8145\n","Epoch 24/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8141\n","Epoch 25/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8169\n","Epoch 26/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3805 - accuracy: 0.8121\n","Epoch 27/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8188\n","Epoch 28/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8151\n","Epoch 29/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.8157\n","Epoch 30/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8200\n","Epoch 31/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8188\n","Epoch 32/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8183\n","Epoch 33/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8179\n","Epoch 34/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8206\n","Epoch 35/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8224\n","Epoch 36/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8196\n","Epoch 37/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8220\n","Epoch 38/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3608 - accuracy: 0.8232\n","Epoch 39/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8252\n","Epoch 40/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8257\n","Epoch 41/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3527 - accuracy: 0.8248\n","Epoch 42/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8259\n","Epoch 43/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8244\n","Epoch 44/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8230\n","Epoch 45/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8295\n","Epoch 46/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3492 - accuracy: 0.8248\n","Epoch 47/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8267\n","Epoch 48/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8315\n","Epoch 49/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8265\n","Epoch 50/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8305\n","53/53 - 0s - loss: 0.3764 - accuracy: 0.8072 - 139ms/epoch - 3ms/step\n","Loss: 0.37644070386886597, Accuracy: 0.8072146773338318\n"]}],"source":["# increasing the units in the second layer\n","nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mBunWpS2_j1_","executionInfo":{"status":"ok","timestamp":1685590318994,"user_tz":420,"elapsed":30618,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"115b85dc-0d89-4931-9551-6b85b1434ea7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.5023 - accuracy: 0.7583\n","Epoch 2/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.4515 - accuracy: 0.7769\n","Epoch 3/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.4330 - accuracy: 0.7871\n","Epoch 4/50\n","159/159 [==============================] - 1s 5ms/step - loss: 0.4269 - accuracy: 0.7883\n","Epoch 5/50\n","159/159 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.7914\n","Epoch 6/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.4173 - accuracy: 0.7960\n","Epoch 7/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.4207 - accuracy: 0.7962\n","Epoch 8/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.4115 - accuracy: 0.8003\n","Epoch 9/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.4066 - accuracy: 0.8013\n","Epoch 10/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.4106 - accuracy: 0.7964\n","Epoch 11/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.4075 - accuracy: 0.8029\n","Epoch 12/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.4034 - accuracy: 0.8003\n","Epoch 13/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.4026 - accuracy: 0.8035\n","Epoch 14/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.4009 - accuracy: 0.8013\n","Epoch 15/50\n","159/159 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8001\n","Epoch 16/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3972 - accuracy: 0.8047\n","Epoch 17/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3984 - accuracy: 0.8037\n","Epoch 18/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3913 - accuracy: 0.8106\n","Epoch 19/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3972 - accuracy: 0.8052\n","Epoch 20/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3943 - accuracy: 0.8019\n","Epoch 21/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3920 - accuracy: 0.8072\n","Epoch 22/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3927 - accuracy: 0.8054\n","Epoch 23/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3903 - accuracy: 0.8045\n","Epoch 24/50\n","159/159 [==============================] - 1s 5ms/step - loss: 0.3875 - accuracy: 0.8090\n","Epoch 25/50\n","159/159 [==============================] - 1s 5ms/step - loss: 0.3865 - accuracy: 0.8108\n","Epoch 26/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3869 - accuracy: 0.8123\n","Epoch 27/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3875 - accuracy: 0.8102\n","Epoch 28/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3843 - accuracy: 0.8139\n","Epoch 29/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3848 - accuracy: 0.8129\n","Epoch 30/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3803 - accuracy: 0.8159\n","Epoch 31/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3821 - accuracy: 0.8131\n","Epoch 32/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3795 - accuracy: 0.8135\n","Epoch 33/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3764 - accuracy: 0.8177\n","Epoch 34/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3777 - accuracy: 0.8117\n","Epoch 35/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3776 - accuracy: 0.8177\n","Epoch 36/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3816 - accuracy: 0.8123\n","Epoch 37/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8173\n","Epoch 38/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3721 - accuracy: 0.8183\n","Epoch 39/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3707 - accuracy: 0.8196\n","Epoch 40/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3687 - accuracy: 0.8218\n","Epoch 41/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3693 - accuracy: 0.8206\n","Epoch 42/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3637 - accuracy: 0.8198\n","Epoch 43/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3663 - accuracy: 0.8234\n","Epoch 44/50\n","159/159 [==============================] - 1s 5ms/step - loss: 0.3631 - accuracy: 0.8204\n","Epoch 45/50\n","159/159 [==============================] - 1s 5ms/step - loss: 0.3650 - accuracy: 0.8177\n","Epoch 46/50\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3595 - accuracy: 0.8242\n","Epoch 47/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3613 - accuracy: 0.8224\n","Epoch 48/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3565 - accuracy: 0.8218\n","Epoch 49/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3572 - accuracy: 0.8218\n","Epoch 50/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3545 - accuracy: 0.8234\n","53/53 - 0s - loss: 0.3892 - accuracy: 0.8019 - 156ms/epoch - 3ms/step\n","Loss: 0.3892420530319214, Accuracy: 0.8018923997879028\n"]}],"source":["# increasing the units in all layers\n","nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=400, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=400, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtiJ6baR_j1_","executionInfo":{"status":"ok","timestamp":1685590373915,"user_tz":420,"elapsed":21744,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"695dc10b-4293-49b9-e65c-4a6e84b44223"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","159/159 [==============================] - 1s 2ms/step - loss: 0.5260 - accuracy: 0.7256\n","Epoch 2/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7859\n","Epoch 3/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7895\n","Epoch 4/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7918\n","Epoch 5/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7901\n","Epoch 6/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8033\n","Epoch 7/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8025\n","Epoch 8/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7958\n","Epoch 9/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8001\n","Epoch 10/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8019\n","Epoch 11/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8076\n","Epoch 12/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8048\n","Epoch 13/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8110\n","Epoch 14/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8017\n","Epoch 15/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8052\n","Epoch 16/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8084\n","Epoch 17/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8080\n","Epoch 18/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8072\n","Epoch 19/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8137\n","Epoch 20/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8141\n","Epoch 21/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8104\n","Epoch 22/50\n","159/159 [==============================] - 1s 6ms/step - loss: 0.3838 - accuracy: 0.8133\n","Epoch 23/50\n","159/159 [==============================] - 1s 5ms/step - loss: 0.3810 - accuracy: 0.8177\n","Epoch 24/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3819 - accuracy: 0.8127\n","Epoch 25/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3796 - accuracy: 0.8163\n","Epoch 26/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8169\n","Epoch 27/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8121\n","Epoch 28/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8163\n","Epoch 29/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8200\n","Epoch 30/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8153\n","Epoch 31/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8135\n","Epoch 32/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8240\n","Epoch 33/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8175\n","Epoch 34/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8192\n","Epoch 35/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8175\n","Epoch 36/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8208\n","Epoch 37/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8192\n","Epoch 38/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8220\n","Epoch 39/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8224\n","Epoch 40/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8212\n","Epoch 41/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8212\n","Epoch 42/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8238\n","Epoch 43/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8202\n","Epoch 44/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8200\n","Epoch 45/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8242\n","Epoch 46/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8289\n","Epoch 47/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8283\n","Epoch 48/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8240\n","Epoch 49/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8303\n","Epoch 50/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8279\n","53/53 - 0s - loss: 0.3780 - accuracy: 0.8173 - 198ms/epoch - 4ms/step\n","Loss: 0.37799885869026184, Accuracy: 0.817267894744873\n"]}],"source":["#adjusting the units  0.37799885869026184, Accuracy: 0.817267894744873\n","\n","nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=400, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"]},{"cell_type":"code","source":["#adding more epochs\n","nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=400, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=150)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1kefw7MXBIBD","executionInfo":{"status":"ok","timestamp":1685590482095,"user_tz":420,"elapsed":60867,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"3efe272d-1d39-4aeb-9447-c48322c74689"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","159/159 [==============================] - 1s 2ms/step - loss: 0.5099 - accuracy: 0.7412\n","Epoch 2/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7822\n","Epoch 3/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7887\n","Epoch 4/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7930\n","Epoch 5/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7926\n","Epoch 6/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7978\n","Epoch 7/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.7995\n","Epoch 8/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8033\n","Epoch 9/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8025\n","Epoch 10/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8035\n","Epoch 11/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8056\n","Epoch 12/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8048\n","Epoch 13/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8054\n","Epoch 14/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8070\n","Epoch 15/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8098\n","Epoch 16/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8100\n","Epoch 17/150\n","159/159 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8072\n","Epoch 18/150\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3904 - accuracy: 0.8102\n","Epoch 19/150\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3872 - accuracy: 0.8129\n","Epoch 20/150\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3856 - accuracy: 0.8116\n","Epoch 21/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8147\n","Epoch 22/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8159\n","Epoch 23/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8210\n","Epoch 24/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8155\n","Epoch 25/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8104\n","Epoch 26/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8169\n","Epoch 27/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8192\n","Epoch 28/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8183\n","Epoch 29/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8185\n","Epoch 30/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8188\n","Epoch 31/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8222\n","Epoch 32/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8194\n","Epoch 33/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8194\n","Epoch 34/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8226\n","Epoch 35/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8285\n","Epoch 36/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8169\n","Epoch 37/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8218\n","Epoch 38/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8240\n","Epoch 39/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8226\n","Epoch 40/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8226\n","Epoch 41/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8240\n","Epoch 42/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8257\n","Epoch 43/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8265\n","Epoch 44/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8334\n","Epoch 45/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8250\n","Epoch 46/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8257\n","Epoch 47/150\n","159/159 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8322\n","Epoch 48/150\n","159/159 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8301\n","Epoch 49/150\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3487 - accuracy: 0.8299\n","Epoch 50/150\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.8257\n","Epoch 51/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8342\n","Epoch 52/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8322\n","Epoch 53/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8291\n","Epoch 54/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8313\n","Epoch 55/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8378\n","Epoch 56/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8356\n","Epoch 57/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8358\n","Epoch 58/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8378\n","Epoch 59/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8386\n","Epoch 60/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8401\n","Epoch 61/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8390\n","Epoch 62/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8399\n","Epoch 63/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8370\n","Epoch 64/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8453\n","Epoch 65/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8409\n","Epoch 66/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8403\n","Epoch 67/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8484\n","Epoch 68/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8441\n","Epoch 69/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8480\n","Epoch 70/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8443\n","Epoch 71/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8466\n","Epoch 72/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8522\n","Epoch 73/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8504\n","Epoch 74/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8480\n","Epoch 75/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8535\n","Epoch 76/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8486\n","Epoch 77/150\n","159/159 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.8498\n","Epoch 78/150\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3021 - accuracy: 0.8535\n","Epoch 79/150\n","159/159 [==============================] - 1s 3ms/step - loss: 0.2992 - accuracy: 0.8547\n","Epoch 80/150\n","159/159 [==============================] - 1s 4ms/step - loss: 0.2963 - accuracy: 0.8555\n","Epoch 81/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8567\n","Epoch 82/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.8563\n","Epoch 83/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8593\n","Epoch 84/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8583\n","Epoch 85/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.8577\n","Epoch 86/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8620\n","Epoch 87/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2882 - accuracy: 0.8591\n","Epoch 88/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.8614\n","Epoch 89/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.8602\n","Epoch 90/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8636\n","Epoch 91/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.8646\n","Epoch 92/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.8587\n","Epoch 93/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.8630\n","Epoch 94/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.8620\n","Epoch 95/150\n","159/159 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.8646\n","Epoch 96/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.8664\n","Epoch 97/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.8624\n","Epoch 98/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8656\n","Epoch 99/150\n","159/159 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.8699\n","Epoch 100/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.8693\n","Epoch 101/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.8673\n","Epoch 102/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.8705\n","Epoch 103/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.8697\n","Epoch 104/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8717\n","Epoch 105/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.8721\n","Epoch 106/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.8719\n","Epoch 107/150\n","159/159 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.8719\n","Epoch 108/150\n","159/159 [==============================] - 1s 3ms/step - loss: 0.2533 - accuracy: 0.8762\n","Epoch 109/150\n","159/159 [==============================] - 1s 4ms/step - loss: 0.2546 - accuracy: 0.8744\n","Epoch 110/150\n","159/159 [==============================] - 1s 3ms/step - loss: 0.2526 - accuracy: 0.8760\n","Epoch 111/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.8750\n","Epoch 112/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8780\n","Epoch 113/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.8770\n","Epoch 114/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.8721\n","Epoch 115/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8796\n","Epoch 116/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.8805\n","Epoch 117/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2401 - accuracy: 0.8831\n","Epoch 118/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.8843\n","Epoch 119/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2389 - accuracy: 0.8817\n","Epoch 120/150\n","159/159 [==============================] - 1s 3ms/step - loss: 0.2411 - accuracy: 0.8839\n","Epoch 121/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2345 - accuracy: 0.8825\n","Epoch 122/150\n","159/159 [==============================] - 1s 3ms/step - loss: 0.2375 - accuracy: 0.8853\n","Epoch 123/150\n","159/159 [==============================] - 0s 3ms/step - loss: 0.2347 - accuracy: 0.8841\n","Epoch 124/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.8845\n","Epoch 125/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.8880\n","Epoch 126/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.8886\n","Epoch 127/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.8904\n","Epoch 128/150\n","159/159 [==============================] - 0s 3ms/step - loss: 0.2276 - accuracy: 0.8869\n","Epoch 129/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.8888\n","Epoch 130/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.8863\n","Epoch 131/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.8900\n","Epoch 132/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.8876\n","Epoch 133/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.8908\n","Epoch 134/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.8914\n","Epoch 135/150\n","159/159 [==============================] - 0s 3ms/step - loss: 0.2235 - accuracy: 0.8878\n","Epoch 136/150\n","159/159 [==============================] - 1s 3ms/step - loss: 0.2189 - accuracy: 0.8890\n","Epoch 137/150\n","159/159 [==============================] - 1s 3ms/step - loss: 0.2167 - accuracy: 0.8920\n","Epoch 138/150\n","159/159 [==============================] - 1s 3ms/step - loss: 0.2146 - accuracy: 0.8943\n","Epoch 139/150\n","159/159 [==============================] - 0s 3ms/step - loss: 0.2158 - accuracy: 0.8938\n","Epoch 140/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.8910\n","Epoch 141/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.8989\n","Epoch 142/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.8945\n","Epoch 143/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.8989\n","Epoch 144/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.8941\n","Epoch 145/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.9014\n","Epoch 146/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.8991\n","Epoch 147/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.8969\n","Epoch 148/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9016\n","Epoch 149/150\n","159/159 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.8959\n","Epoch 150/150\n","159/159 [==============================] - 0s 3ms/step - loss: 0.2011 - accuracy: 0.8983\n","53/53 - 0s - loss: 0.6143 - accuracy: 0.7907 - 154ms/epoch - 3ms/step\n","Loss: 0.6143184304237366, Accuracy: 0.7906563878059387\n"]}]},{"cell_type":"code","source":["# training the model: Loss: 0.3851335644721985, Accuracy: 0.822590172290802\n","\n","nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hWlYrOBoBINR","executionInfo":{"status":"ok","timestamp":1685591017917,"user_tz":420,"elapsed":22068,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"dc01db7d-d729-448f-9030-b94d13651092"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","159/159 [==============================] - 1s 2ms/step - loss: 0.5832 - accuracy: 0.6617\n","Epoch 2/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7879\n","Epoch 3/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7877\n","Epoch 4/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7946\n","Epoch 5/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7944\n","Epoch 6/50\n","159/159 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.7995\n","Epoch 7/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7981\n","Epoch 8/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7944\n","Epoch 9/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8015\n","Epoch 10/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8035\n","Epoch 11/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8064\n","Epoch 12/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8039\n","Epoch 13/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8047\n","Epoch 14/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8054\n","Epoch 15/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.7985\n","Epoch 16/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8086\n","Epoch 17/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8064\n","Epoch 18/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8060\n","Epoch 19/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8060\n","Epoch 20/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8112\n","Epoch 21/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8125\n","Epoch 22/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8041\n","Epoch 23/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8117\n","Epoch 24/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8121\n","Epoch 25/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8102\n","Epoch 26/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8117\n","Epoch 27/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8127\n","Epoch 28/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8116\n","Epoch 29/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8141\n","Epoch 30/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8114\n","Epoch 31/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8157\n","Epoch 32/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8149\n","Epoch 33/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8143\n","Epoch 34/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8106\n","Epoch 35/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8179\n","Epoch 36/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8125\n","Epoch 37/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8149\n","Epoch 38/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8141\n","Epoch 39/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8173\n","Epoch 40/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8149\n","Epoch 41/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8186\n","Epoch 42/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8161\n","Epoch 43/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8181\n","Epoch 44/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8188\n","Epoch 45/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8151\n","Epoch 46/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8196\n","Epoch 47/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8220\n","Epoch 48/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8186\n","Epoch 49/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8185\n","Epoch 50/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8218\n","53/53 - 0s - loss: 0.3914 - accuracy: 0.8185 - 143ms/epoch - 3ms/step\n","Loss: 0.3913896977901459, Accuracy: 0.8184506297111511\n"]}]},{"cell_type":"code","source":["# Loss: 0.380045086145401, Accuracy: 0.8202247023582458\n","\n","nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qw5VNIKgDyt3","executionInfo":{"status":"ok","timestamp":1685591139548,"user_tz":420,"elapsed":21692,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"680a902d-a730-404a-8b18-0057df0514f7"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","159/159 [==============================] - 1s 2ms/step - loss: 0.6910 - accuracy: 0.5326\n","Epoch 2/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7810\n","Epoch 3/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7918\n","Epoch 4/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7966\n","Epoch 5/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.7954\n","Epoch 6/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7944\n","Epoch 7/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7993\n","Epoch 8/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7983\n","Epoch 9/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8011\n","Epoch 10/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8011\n","Epoch 11/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8041\n","Epoch 12/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8007\n","Epoch 13/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8056\n","Epoch 14/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8011\n","Epoch 15/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.7985\n","Epoch 16/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8001\n","Epoch 17/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8035\n","Epoch 18/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8047\n","Epoch 19/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8084\n","Epoch 20/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8090\n","Epoch 21/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8108\n","Epoch 22/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8076\n","Epoch 23/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8082\n","Epoch 24/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8084\n","Epoch 25/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8098\n","Epoch 26/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8112\n","Epoch 27/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8094\n","Epoch 28/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8112\n","Epoch 29/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8066\n","Epoch 30/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8147\n","Epoch 31/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8163\n","Epoch 32/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8086\n","Epoch 33/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8119\n","Epoch 34/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8117\n","Epoch 35/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8204\n","Epoch 36/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8173\n","Epoch 37/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8173\n","Epoch 38/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8141\n","Epoch 39/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8165\n","Epoch 40/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8169\n","Epoch 41/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8155\n","Epoch 42/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8185\n","Epoch 43/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8208\n","Epoch 44/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8220\n","Epoch 45/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8151\n","Epoch 46/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8181\n","Epoch 47/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8202\n","Epoch 48/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8208\n","Epoch 49/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8161\n","Epoch 50/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8210\n","53/53 - 0s - loss: 0.3800 - accuracy: 0.8202 - 144ms/epoch - 3ms/step\n","Loss: 0.380045086145401, Accuracy: 0.8202247023582458\n"]}]},{"cell_type":"code","source":["nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=100)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1UVpWV06DysS","executionInfo":{"status":"ok","timestamp":1685591722590,"user_tz":420,"elapsed":36586,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"b18758dd-5e28-4c7e-9476-aa5767a0753b"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","159/159 [==============================] - 1s 2ms/step - loss: 0.6469 - accuracy: 0.5801\n","Epoch 2/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7863\n","Epoch 3/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7924\n","Epoch 4/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7922\n","Epoch 5/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7922\n","Epoch 6/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7956\n","Epoch 7/100\n","159/159 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.7985\n","Epoch 8/100\n","159/159 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8015\n","Epoch 9/100\n","159/159 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8025\n","Epoch 10/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8017\n","Epoch 11/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8021\n","Epoch 12/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8043\n","Epoch 13/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8035\n","Epoch 14/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8062\n","Epoch 15/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.7997\n","Epoch 16/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8035\n","Epoch 17/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8070\n","Epoch 18/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.7999\n","Epoch 19/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8047\n","Epoch 20/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8050\n","Epoch 21/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8052\n","Epoch 22/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8074\n","Epoch 23/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8112\n","Epoch 24/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8043\n","Epoch 25/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8078\n","Epoch 26/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8066\n","Epoch 27/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8088\n","Epoch 28/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8068\n","Epoch 29/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8135\n","Epoch 30/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8100\n","Epoch 31/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8112\n","Epoch 32/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8117\n","Epoch 33/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8096\n","Epoch 34/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8119\n","Epoch 35/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8116\n","Epoch 36/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8127\n","Epoch 37/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8121\n","Epoch 38/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8125\n","Epoch 39/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8143\n","Epoch 40/100\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3782 - accuracy: 0.8163\n","Epoch 41/100\n","159/159 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8161\n","Epoch 42/100\n","159/159 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8123\n","Epoch 43/100\n","159/159 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8131\n","Epoch 44/100\n","159/159 [==============================] - 0s 3ms/step - loss: 0.3805 - accuracy: 0.8110\n","Epoch 45/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8165\n","Epoch 46/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8137\n","Epoch 47/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8153\n","Epoch 48/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8214\n","Epoch 49/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8202\n","Epoch 50/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8186\n","Epoch 51/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8204\n","Epoch 52/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8175\n","Epoch 53/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8208\n","Epoch 54/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8220\n","Epoch 55/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8220\n","Epoch 56/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8220\n","Epoch 57/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8208\n","Epoch 58/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8238\n","Epoch 59/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8255\n","Epoch 60/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8236\n","Epoch 61/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8185\n","Epoch 62/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8238\n","Epoch 63/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8220\n","Epoch 64/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8224\n","Epoch 65/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8218\n","Epoch 66/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8242\n","Epoch 67/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8220\n","Epoch 68/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8242\n","Epoch 69/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8244\n","Epoch 70/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8210\n","Epoch 71/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8232\n","Epoch 72/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8222\n","Epoch 73/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8214\n","Epoch 74/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8238\n","Epoch 75/100\n","159/159 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8220\n","Epoch 76/100\n","159/159 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8202\n","Epoch 77/100\n","159/159 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8242\n","Epoch 78/100\n","159/159 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8259\n","Epoch 79/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8283\n","Epoch 80/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8250\n","Epoch 81/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8257\n","Epoch 82/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8244\n","Epoch 83/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8277\n","Epoch 84/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8311\n","Epoch 85/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8267\n","Epoch 86/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8283\n","Epoch 87/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8291\n","Epoch 88/100\n","159/159 [==============================] - 1s 3ms/step - loss: 0.3462 - accuracy: 0.8269\n","Epoch 89/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8307\n","Epoch 90/100\n","159/159 [==============================] - 1s 4ms/step - loss: 0.3432 - accuracy: 0.8285\n","Epoch 91/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8259\n","Epoch 92/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8328\n","Epoch 93/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8287\n","Epoch 94/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8252\n","Epoch 95/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8317\n","Epoch 96/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8287\n","Epoch 97/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8311\n","Epoch 98/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8279\n","Epoch 99/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8275\n","Epoch 100/100\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8322\n","53/53 - 0s - loss: 0.4100 - accuracy: 0.8043 - 172ms/epoch - 3ms/step\n","Loss: 0.410020112991333, Accuracy: 0.8042578101158142\n"]}]},{"cell_type":"code","source":["#adding more layers Loss: 0.39267197251319885, Accuracy: 0.8072146773338318\n","\n","nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=200, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1Fvs_oKDyps","executionInfo":{"status":"ok","timestamp":1685592336088,"user_tz":420,"elapsed":21939,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"175f14ca-690d-4168-bdc3-5550255d95ea"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","159/159 [==============================] - 1s 2ms/step - loss: 0.6934 - accuracy: 0.4985\n","Epoch 2/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5029\n","Epoch 3/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4969\n","Epoch 4/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5001\n","Epoch 5/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4944\n","Epoch 6/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5011\n","Epoch 7/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7236\n","Epoch 8/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7879\n","Epoch 9/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7928\n","Epoch 10/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7930\n","Epoch 11/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7983\n","Epoch 12/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7952\n","Epoch 13/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7964\n","Epoch 14/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7979\n","Epoch 15/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7983\n","Epoch 16/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8017\n","Epoch 17/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7995\n","Epoch 18/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7989\n","Epoch 19/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8043\n","Epoch 20/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8027\n","Epoch 21/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8058\n","Epoch 22/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.7995\n","Epoch 23/50\n","159/159 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8037\n","Epoch 24/50\n","159/159 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8054\n","Epoch 25/50\n","159/159 [==============================] - 1s 3ms/step - loss: 0.4017 - accuracy: 0.8052\n","Epoch 26/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8054\n","Epoch 27/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8064\n","Epoch 28/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8047\n","Epoch 29/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8078\n","Epoch 30/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8043\n","Epoch 31/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8078\n","Epoch 32/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8066\n","Epoch 33/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8070\n","Epoch 34/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8088\n","Epoch 35/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8100\n","Epoch 36/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8078\n","Epoch 37/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8108\n","Epoch 38/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8112\n","Epoch 39/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8096\n","Epoch 40/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8048\n","Epoch 41/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8155\n","Epoch 42/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8106\n","Epoch 43/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8108\n","Epoch 44/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8082\n","Epoch 45/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8139\n","Epoch 46/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8125\n","Epoch 47/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8112\n","Epoch 48/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8147\n","Epoch 49/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8141\n","Epoch 50/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8108\n","53/53 - 0s - loss: 0.3927 - accuracy: 0.8072 - 170ms/epoch - 3ms/step\n","Loss: 0.39267197251319885, Accuracy: 0.8072146773338318\n"]}]},{"cell_type":"code","source":["#Loss: 0.3881196081638336, Accuracy: 0.816085159778595\n","nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=1000, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=1000, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=80)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E0XM1WWQDynX","executionInfo":{"status":"ok","timestamp":1685593042528,"user_tz":420,"elapsed":203083,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"aa4153da-be39-4969-ef48-e6231cc7a663"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","159/159 [==============================] - 3s 12ms/step - loss: 0.6283 - accuracy: 0.6241\n","Epoch 2/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.4527 - accuracy: 0.7857\n","Epoch 3/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.4328 - accuracy: 0.7934\n","Epoch 4/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.4236 - accuracy: 0.7962\n","Epoch 5/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.4204 - accuracy: 0.7914\n","Epoch 6/80\n","159/159 [==============================] - 2s 15ms/step - loss: 0.4159 - accuracy: 0.7985\n","Epoch 7/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.4154 - accuracy: 0.8003\n","Epoch 8/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.4151 - accuracy: 0.8019\n","Epoch 9/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.4090 - accuracy: 0.7995\n","Epoch 10/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.4089 - accuracy: 0.7991\n","Epoch 11/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.4084 - accuracy: 0.8019\n","Epoch 12/80\n","159/159 [==============================] - 2s 15ms/step - loss: 0.4073 - accuracy: 0.8045\n","Epoch 13/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.4072 - accuracy: 0.8031\n","Epoch 14/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.4041 - accuracy: 0.8074\n","Epoch 15/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.4037 - accuracy: 0.8031\n","Epoch 16/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.4042 - accuracy: 0.8039\n","Epoch 17/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.4020 - accuracy: 0.8043\n","Epoch 18/80\n","159/159 [==============================] - 2s 13ms/step - loss: 0.4024 - accuracy: 0.8056\n","Epoch 19/80\n","159/159 [==============================] - 2s 13ms/step - loss: 0.3996 - accuracy: 0.8064\n","Epoch 20/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.4002 - accuracy: 0.8082\n","Epoch 21/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.4004 - accuracy: 0.8048\n","Epoch 22/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.4012 - accuracy: 0.8027\n","Epoch 23/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3988 - accuracy: 0.8092\n","Epoch 24/80\n","159/159 [==============================] - 2s 13ms/step - loss: 0.3988 - accuracy: 0.8090\n","Epoch 25/80\n","159/159 [==============================] - 2s 13ms/step - loss: 0.3968 - accuracy: 0.8033\n","Epoch 26/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3966 - accuracy: 0.8084\n","Epoch 27/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3954 - accuracy: 0.8064\n","Epoch 28/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3962 - accuracy: 0.8070\n","Epoch 29/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3943 - accuracy: 0.8029\n","Epoch 30/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3924 - accuracy: 0.8117\n","Epoch 31/80\n","159/159 [==============================] - 2s 15ms/step - loss: 0.3950 - accuracy: 0.8058\n","Epoch 32/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3936 - accuracy: 0.8074\n","Epoch 33/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3913 - accuracy: 0.8094\n","Epoch 34/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3948 - accuracy: 0.8070\n","Epoch 35/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3909 - accuracy: 0.8119\n","Epoch 36/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3892 - accuracy: 0.8108\n","Epoch 37/80\n","159/159 [==============================] - 2s 15ms/step - loss: 0.3886 - accuracy: 0.8106\n","Epoch 38/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3916 - accuracy: 0.8066\n","Epoch 39/80\n","159/159 [==============================] - 2s 13ms/step - loss: 0.3894 - accuracy: 0.8100\n","Epoch 40/80\n","159/159 [==============================] - 2s 14ms/step - loss: 0.3886 - accuracy: 0.8119\n","Epoch 41/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3849 - accuracy: 0.8185\n","Epoch 42/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3866 - accuracy: 0.8135\n","Epoch 43/80\n","159/159 [==============================] - 2s 14ms/step - loss: 0.3850 - accuracy: 0.8135\n","Epoch 44/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3841 - accuracy: 0.8157\n","Epoch 45/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3827 - accuracy: 0.8141\n","Epoch 46/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3852 - accuracy: 0.8165\n","Epoch 47/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3815 - accuracy: 0.8155\n","Epoch 48/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3838 - accuracy: 0.8177\n","Epoch 49/80\n","159/159 [==============================] - 2s 15ms/step - loss: 0.3786 - accuracy: 0.8202\n","Epoch 50/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3813 - accuracy: 0.8171\n","Epoch 51/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3798 - accuracy: 0.8188\n","Epoch 52/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3785 - accuracy: 0.8104\n","Epoch 53/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3780 - accuracy: 0.8131\n","Epoch 54/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3773 - accuracy: 0.8169\n","Epoch 55/80\n","159/159 [==============================] - 3s 16ms/step - loss: 0.3756 - accuracy: 0.8177\n","Epoch 56/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3775 - accuracy: 0.8153\n","Epoch 57/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3763 - accuracy: 0.8161\n","Epoch 58/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3751 - accuracy: 0.8163\n","Epoch 59/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3747 - accuracy: 0.8173\n","Epoch 60/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3737 - accuracy: 0.8188\n","Epoch 61/80\n","159/159 [==============================] - 2s 16ms/step - loss: 0.3711 - accuracy: 0.8214\n","Epoch 62/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3726 - accuracy: 0.8208\n","Epoch 63/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3733 - accuracy: 0.8190\n","Epoch 64/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3703 - accuracy: 0.8234\n","Epoch 65/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3713 - accuracy: 0.8198\n","Epoch 66/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3706 - accuracy: 0.8161\n","Epoch 67/80\n","159/159 [==============================] - 2s 15ms/step - loss: 0.3724 - accuracy: 0.8171\n","Epoch 68/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3668 - accuracy: 0.8236\n","Epoch 69/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3701 - accuracy: 0.8188\n","Epoch 70/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3676 - accuracy: 0.8244\n","Epoch 71/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3673 - accuracy: 0.8196\n","Epoch 72/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3667 - accuracy: 0.8228\n","Epoch 73/80\n","159/159 [==============================] - 3s 16ms/step - loss: 0.3659 - accuracy: 0.8224\n","Epoch 74/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3644 - accuracy: 0.8216\n","Epoch 75/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3689 - accuracy: 0.8192\n","Epoch 76/80\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3661 - accuracy: 0.8194\n","Epoch 77/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3653 - accuracy: 0.8200\n","Epoch 78/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3615 - accuracy: 0.8232\n","Epoch 79/80\n","159/159 [==============================] - 3s 16ms/step - loss: 0.3607 - accuracy: 0.8228\n","Epoch 80/80\n","159/159 [==============================] - 2s 12ms/step - loss: 0.3619 - accuracy: 0.8248\n","53/53 - 0s - loss: 0.3881 - accuracy: 0.8161 - 218ms/epoch - 4ms/step\n","Loss: 0.3881196081638336, Accuracy: 0.816085159778595\n"]}]},{"cell_type":"code","source":["nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=2000, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=2000, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZ4l23ttDyjL","executionInfo":{"status":"ok","timestamp":1685593446140,"user_tz":420,"elapsed":323564,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"35fc8ce4-34be-4677-8127-71605c7705f9"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","159/159 [==============================] - 6s 36ms/step - loss: 0.6912 - accuracy: 0.5194\n","Epoch 2/50\n","159/159 [==============================] - 6s 41ms/step - loss: 0.4790 - accuracy: 0.7721\n","Epoch 3/50\n","159/159 [==============================] - 6s 37ms/step - loss: 0.4337 - accuracy: 0.7893\n","Epoch 4/50\n","159/159 [==============================] - 6s 38ms/step - loss: 0.4246 - accuracy: 0.7914\n","Epoch 5/50\n","159/159 [==============================] - 6s 35ms/step - loss: 0.4176 - accuracy: 0.7952\n","Epoch 6/50\n","159/159 [==============================] - 6s 38ms/step - loss: 0.4148 - accuracy: 0.7976\n","Epoch 7/50\n","159/159 [==============================] - 6s 35ms/step - loss: 0.4127 - accuracy: 0.8007\n","Epoch 8/50\n","159/159 [==============================] - 6s 39ms/step - loss: 0.4112 - accuracy: 0.8023\n","Epoch 9/50\n","159/159 [==============================] - 6s 35ms/step - loss: 0.4124 - accuracy: 0.8003\n","Epoch 10/50\n","159/159 [==============================] - 7s 43ms/step - loss: 0.4094 - accuracy: 0.8048\n","Epoch 11/50\n","159/159 [==============================] - 7s 45ms/step - loss: 0.4061 - accuracy: 0.8058\n","Epoch 12/50\n","159/159 [==============================] - 6s 36ms/step - loss: 0.4059 - accuracy: 0.8084\n","Epoch 13/50\n","159/159 [==============================] - 6s 41ms/step - loss: 0.4053 - accuracy: 0.8072\n","Epoch 14/50\n","159/159 [==============================] - 6s 36ms/step - loss: 0.4027 - accuracy: 0.8048\n","Epoch 15/50\n","159/159 [==============================] - 6s 41ms/step - loss: 0.4022 - accuracy: 0.8092\n","Epoch 16/50\n","159/159 [==============================] - 7s 41ms/step - loss: 0.4023 - accuracy: 0.8035\n","Epoch 17/50\n","159/159 [==============================] - 7s 47ms/step - loss: 0.4020 - accuracy: 0.8043\n","Epoch 18/50\n","159/159 [==============================] - 10s 65ms/step - loss: 0.4038 - accuracy: 0.8045\n","Epoch 19/50\n","159/159 [==============================] - 9s 56ms/step - loss: 0.3992 - accuracy: 0.8048\n","Epoch 20/50\n","159/159 [==============================] - 6s 40ms/step - loss: 0.3972 - accuracy: 0.8033\n","Epoch 21/50\n","159/159 [==============================] - 6s 36ms/step - loss: 0.4010 - accuracy: 0.8068\n","Epoch 22/50\n","159/159 [==============================] - 6s 39ms/step - loss: 0.3973 - accuracy: 0.8090\n","Epoch 23/50\n","159/159 [==============================] - 6s 36ms/step - loss: 0.3957 - accuracy: 0.8090\n","Epoch 24/50\n","159/159 [==============================] - 6s 40ms/step - loss: 0.3952 - accuracy: 0.8039\n","Epoch 25/50\n","159/159 [==============================] - 6s 37ms/step - loss: 0.3949 - accuracy: 0.8094\n","Epoch 26/50\n","159/159 [==============================] - 6s 38ms/step - loss: 0.4011 - accuracy: 0.8031\n","Epoch 27/50\n","159/159 [==============================] - 6s 37ms/step - loss: 0.3921 - accuracy: 0.8096\n","Epoch 28/50\n","159/159 [==============================] - 6s 39ms/step - loss: 0.3915 - accuracy: 0.8110\n","Epoch 29/50\n","159/159 [==============================] - 6s 39ms/step - loss: 0.3906 - accuracy: 0.8116\n","Epoch 30/50\n","159/159 [==============================] - 6s 35ms/step - loss: 0.3891 - accuracy: 0.8117\n","Epoch 31/50\n","159/159 [==============================] - 5s 33ms/step - loss: 0.3893 - accuracy: 0.8086\n","Epoch 32/50\n","159/159 [==============================] - 6s 38ms/step - loss: 0.3883 - accuracy: 0.8088\n","Epoch 33/50\n","159/159 [==============================] - 5s 33ms/step - loss: 0.3902 - accuracy: 0.8102\n","Epoch 34/50\n","159/159 [==============================] - 6s 40ms/step - loss: 0.3896 - accuracy: 0.8090\n","Epoch 35/50\n","159/159 [==============================] - 6s 37ms/step - loss: 0.3854 - accuracy: 0.8163\n","Epoch 36/50\n","159/159 [==============================] - 6s 40ms/step - loss: 0.3884 - accuracy: 0.8102\n","Epoch 37/50\n","159/159 [==============================] - 6s 37ms/step - loss: 0.3844 - accuracy: 0.8133\n","Epoch 38/50\n","159/159 [==============================] - 7s 42ms/step - loss: 0.3872 - accuracy: 0.8076\n","Epoch 39/50\n","159/159 [==============================] - 6s 36ms/step - loss: 0.3850 - accuracy: 0.8127\n","Epoch 40/50\n","159/159 [==============================] - 6s 40ms/step - loss: 0.3847 - accuracy: 0.8163\n","Epoch 41/50\n","159/159 [==============================] - 6s 38ms/step - loss: 0.3840 - accuracy: 0.8112\n","Epoch 42/50\n","159/159 [==============================] - 6s 40ms/step - loss: 0.3795 - accuracy: 0.8214\n","Epoch 43/50\n","159/159 [==============================] - 6s 40ms/step - loss: 0.3819 - accuracy: 0.8129\n","Epoch 44/50\n","159/159 [==============================] - 6s 37ms/step - loss: 0.3785 - accuracy: 0.8175\n","Epoch 45/50\n","159/159 [==============================] - 6s 38ms/step - loss: 0.3782 - accuracy: 0.8185\n","Epoch 46/50\n","159/159 [==============================] - 6s 38ms/step - loss: 0.3771 - accuracy: 0.8157\n","Epoch 47/50\n","159/159 [==============================] - 7s 42ms/step - loss: 0.3801 - accuracy: 0.8153\n","Epoch 48/50\n","159/159 [==============================] - 6s 37ms/step - loss: 0.3792 - accuracy: 0.8133\n","Epoch 49/50\n","159/159 [==============================] - 7s 41ms/step - loss: 0.3750 - accuracy: 0.8212\n","Epoch 50/50\n","159/159 [==============================] - 6s 36ms/step - loss: 0.3766 - accuracy: 0.8204\n","53/53 - 0s - loss: 0.3858 - accuracy: 0.8137 - 409ms/epoch - 8ms/step\n","Loss: 0.3857726752758026, Accuracy: 0.8137196898460388\n"]}]},{"cell_type":"code","source":["nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yLmy-XdvDyan","executionInfo":{"status":"ok","timestamp":1685593480855,"user_tz":420,"elapsed":21437,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"69ac2c6e-1879-4ac1-f063-f41baf28aa79"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","159/159 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4977\n","Epoch 2/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5025\n","Epoch 3/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n","Epoch 4/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5029\n","Epoch 5/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5060\n","Epoch 6/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5029\n","Epoch 7/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5017\n","Epoch 8/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5121\n","Epoch 9/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5029\n","Epoch 10/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5034\n","Epoch 11/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5036\n","Epoch 12/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5038\n","Epoch 13/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5151\n","Epoch 14/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5052\n","Epoch 15/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.5031\n","Epoch 16/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5157\n","Epoch 17/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5029\n","Epoch 18/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5084\n","Epoch 19/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5034\n","Epoch 20/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5034\n","Epoch 21/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5080\n","Epoch 22/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5184\n","Epoch 23/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5159\n","Epoch 24/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5058\n","Epoch 25/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5316\n","Epoch 26/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5098\n","Epoch 27/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5029\n","Epoch 28/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5287\n","Epoch 29/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5082\n","Epoch 30/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5031\n","Epoch 31/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5029\n","Epoch 32/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5241\n","Epoch 33/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5092\n","Epoch 34/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5050\n","Epoch 35/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5275\n","Epoch 36/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5062\n","Epoch 37/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5054\n","Epoch 38/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5109\n","Epoch 39/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5092\n","Epoch 40/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5208\n","Epoch 41/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5029\n","Epoch 42/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5423\n","Epoch 43/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5033\n","Epoch 44/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5098\n","Epoch 45/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5399\n","Epoch 46/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5167\n","Epoch 47/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5557\n","Epoch 48/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5033\n","Epoch 49/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5029\n","Epoch 50/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5226\n","53/53 - 0s - loss: 0.6927 - accuracy: 0.5027 - 144ms/epoch - 3ms/step\n","Loss: 0.6926923394203186, Accuracy: 0.5026611685752869\n"]}]},{"cell_type":"code","source":["nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"RMSProp\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YMmEI8KXL5Am","executionInfo":{"status":"ok","timestamp":1685593594154,"user_tz":420,"elapsed":97556,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"acff5ac5-b32f-417a-d854-fc1c88cf87b4"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","159/159 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5435\n","Epoch 2/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7410\n","Epoch 3/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7820\n","Epoch 4/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7938\n","Epoch 5/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.7942\n","Epoch 6/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.7924\n","Epoch 7/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4219 - accuracy: 0.7920\n","Epoch 8/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4199 - accuracy: 0.7952\n","Epoch 9/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.7916\n","Epoch 10/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4168 - accuracy: 0.7954\n","Epoch 11/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.7993\n","Epoch 12/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.7989\n","Epoch 13/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.7974\n","Epoch 14/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.8019\n","Epoch 15/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.8039\n","Epoch 16/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4092 - accuracy: 0.8041\n","Epoch 17/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4074 - accuracy: 0.8011\n","Epoch 18/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8045\n","Epoch 19/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4049 - accuracy: 0.8056\n","Epoch 20/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8047\n","Epoch 21/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8009\n","Epoch 22/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8017\n","Epoch 23/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4001 - accuracy: 0.8125\n","Epoch 24/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.8047\n","Epoch 25/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8074\n","Epoch 26/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.4001 - accuracy: 0.8043\n","Epoch 27/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3993 - accuracy: 0.8050\n","Epoch 28/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3990 - accuracy: 0.8033\n","Epoch 29/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3969 - accuracy: 0.8070\n","Epoch 30/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8082\n","Epoch 31/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.8045\n","Epoch 32/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3948 - accuracy: 0.8050\n","Epoch 33/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3941 - accuracy: 0.8086\n","Epoch 34/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8076\n","Epoch 35/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.8104\n","Epoch 36/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3925 - accuracy: 0.8058\n","Epoch 37/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.8098\n","Epoch 38/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8112\n","Epoch 39/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3894 - accuracy: 0.8110\n","Epoch 40/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3895 - accuracy: 0.8106\n","Epoch 41/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8080\n","Epoch 42/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3886 - accuracy: 0.8137\n","Epoch 43/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.8116\n","Epoch 44/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8096\n","Epoch 45/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3868 - accuracy: 0.8145\n","Epoch 46/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3854 - accuracy: 0.8183\n","Epoch 47/50\n","159/159 [==============================] - 0s 1ms/step - loss: 0.3866 - accuracy: 0.8139\n","Epoch 48/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8098\n","Epoch 49/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8151\n","Epoch 50/50\n","159/159 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8110\n","53/53 - 0s - loss: 0.3907 - accuracy: 0.8167 - 151ms/epoch - 3ms/step\n","Loss: 0.39067506790161133, Accuracy: 0.8166764974594116\n"]}]},{"cell_type":"code","source":["nn_model = tf.keras.models.Sequential()\n","nn_model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\", input_dim=25))\n","nn_model.add(tf.keras.layers.Dense(units=1000, activation=\"softmax\"))\n","nn_model.add(tf.keras.layers.Dense(units=1000, activation=\"relu\"))\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","\n","# Compile the Sequential model together and customize metrics\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"Adamax\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","fit_model = nn_model.fit(X_train_scaled,y_train,epochs=50)\n","\n","# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AeC8_VemL4-g","executionInfo":{"status":"ok","timestamp":1685593754063,"user_tz":420,"elapsed":85167,"user":{"displayName":"Joshua Feinberg","userId":"10882198606027080634"}},"outputId":"a089305d-4127-4a9f-c0cd-9045234abad8"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","159/159 [==============================] - 3s 12ms/step - loss: 0.6929 - accuracy: 0.4952\n","Epoch 2/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.6579 - accuracy: 0.6789\n","Epoch 3/50\n","159/159 [==============================] - 2s 9ms/step - loss: 0.5301 - accuracy: 0.7548\n","Epoch 4/50\n","159/159 [==============================] - 2s 11ms/step - loss: 0.4813 - accuracy: 0.7680\n","Epoch 5/50\n","159/159 [==============================] - 2s 13ms/step - loss: 0.4668 - accuracy: 0.7808\n","Epoch 6/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4553 - accuracy: 0.7820\n","Epoch 7/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4480 - accuracy: 0.7887\n","Epoch 8/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4419 - accuracy: 0.7881\n","Epoch 9/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4386 - accuracy: 0.7879\n","Epoch 10/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4344 - accuracy: 0.7914\n","Epoch 11/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4308 - accuracy: 0.7940\n","Epoch 12/50\n","159/159 [==============================] - 2s 14ms/step - loss: 0.4272 - accuracy: 0.7942\n","Epoch 13/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4265 - accuracy: 0.7952\n","Epoch 14/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4232 - accuracy: 0.7950\n","Epoch 15/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4215 - accuracy: 0.7968\n","Epoch 16/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4213 - accuracy: 0.7989\n","Epoch 17/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4203 - accuracy: 0.7956\n","Epoch 18/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4187 - accuracy: 0.7995\n","Epoch 19/50\n","159/159 [==============================] - 2s 14ms/step - loss: 0.4176 - accuracy: 0.7985\n","Epoch 20/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4165 - accuracy: 0.8005\n","Epoch 21/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4138 - accuracy: 0.7983\n","Epoch 22/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4133 - accuracy: 0.7989\n","Epoch 23/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4142 - accuracy: 0.7985\n","Epoch 24/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4127 - accuracy: 0.8011\n","Epoch 25/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4114 - accuracy: 0.8001\n","Epoch 26/50\n","159/159 [==============================] - 2s 14ms/step - loss: 0.4104 - accuracy: 0.8023\n","Epoch 27/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4095 - accuracy: 0.8029\n","Epoch 28/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4093 - accuracy: 0.8015\n","Epoch 29/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4083 - accuracy: 0.8031\n","Epoch 30/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4093 - accuracy: 0.7989\n","Epoch 31/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4072 - accuracy: 0.8021\n","Epoch 32/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4069 - accuracy: 0.8039\n","Epoch 33/50\n","159/159 [==============================] - 2s 13ms/step - loss: 0.4070 - accuracy: 0.8047\n","Epoch 34/50\n","159/159 [==============================] - 2s 11ms/step - loss: 0.4045 - accuracy: 0.8035\n","Epoch 35/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4046 - accuracy: 0.8033\n","Epoch 36/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4047 - accuracy: 0.8080\n","Epoch 37/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4048 - accuracy: 0.8068\n","Epoch 38/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4032 - accuracy: 0.8088\n","Epoch 39/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4026 - accuracy: 0.8025\n","Epoch 40/50\n","159/159 [==============================] - 2s 12ms/step - loss: 0.4033 - accuracy: 0.8066\n","Epoch 41/50\n","159/159 [==============================] - 2s 12ms/step - loss: 0.4034 - accuracy: 0.8078\n","Epoch 42/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4028 - accuracy: 0.8037\n","Epoch 43/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4038 - accuracy: 0.8054\n","Epoch 44/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4032 - accuracy: 0.8092\n","Epoch 45/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4023 - accuracy: 0.8045\n","Epoch 46/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4012 - accuracy: 0.8086\n","Epoch 47/50\n","159/159 [==============================] - 2s 11ms/step - loss: 0.4015 - accuracy: 0.8050\n","Epoch 48/50\n","159/159 [==============================] - 2s 12ms/step - loss: 0.4014 - accuracy: 0.8054\n","Epoch 49/50\n","159/159 [==============================] - 2s 10ms/step - loss: 0.4009 - accuracy: 0.8033\n","Epoch 50/50\n","159/159 [==============================] - 2s 11ms/step - loss: 0.3995 - accuracy: 0.8045\n","53/53 - 0s - loss: 0.4062 - accuracy: 0.7983 - 208ms/epoch - 4ms/step\n","Loss: 0.40624549984931946, Accuracy: 0.7983441948890686\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"flBABLcQL475"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1FuYAuyhL42d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"J1weObJtL4tE"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"colab":{"provenance":[{"file_id":"1Yomc8Q2i-2dqWdZMofC23VxhZGEv6DXY","timestamp":1685670189595}]}},"nbformat":4,"nbformat_minor":0}